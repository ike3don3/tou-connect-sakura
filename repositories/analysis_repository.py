#!/usr/bin/env python3
"""
åˆ†æçµæœãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ©ã‚¹
User_Analysisãƒ†ãƒ¼ãƒ–ãƒ«ã®æ“ä½œã‚’ç®¡ç†
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import json
import re
from datetime import datetime
from typing import Optional, Dict, List, Any
import logging
from database.database_manager import DatabaseManager, AnalysisError, json_to_text, text_to_json

logger = logging.getLogger(__name__)

class AnalysisRepository:
    """AIåˆ†æçµæœã®æ°¸ç¶šåŒ–ã‚’ç®¡ç†ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_manager: DatabaseManager):
        """
        åˆ†æãƒªãƒã‚¸ãƒˆãƒªã®åˆæœŸåŒ–
        
        Args:
            db_manager: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.db = db_manager
    
    def save_analysis(self, user_id: int, analysis_data: Dict[str, Any]) -> int:
        """
        AIåˆ†æçµæœã‚’ä¿å­˜
        
        Args:
            user_id: å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ID
            analysis_data: Gemini APIã‹ã‚‰ã®åˆ†æçµæœ
            
        Returns:
            ä¿å­˜ã•ã‚ŒãŸåˆ†æãƒ¬ã‚³ãƒ¼ãƒ‰ã®ID
        """
        try:
            # æ—¢å­˜ã®åˆ†æçµæœã‚’ç¢ºèª
            existing_analysis = self.get_latest_analysis(user_id)
            
            # åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’è§£æãƒ»æ§‹é€ åŒ–
            structured_data = self._parse_analysis_data(analysis_data)
            
            if existing_analysis:
                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
                return self._update_analysis(existing_analysis['id'], structured_data)
            else:
                # æ–°è¦ä½œæˆ
                return self._create_analysis(user_id, structured_data)
                
        except Exception as e:
            logger.error(f"åˆ†æãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise AnalysisError(f"åˆ†æãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«å¤±æ•—: {e}")
    
    def _parse_analysis_data(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Gemini APIã®åˆ†æçµæœã‚’æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
        
        Args:
            analysis_data: ç”Ÿã®åˆ†æãƒ‡ãƒ¼ã‚¿
            
        Returns:
            æ§‹é€ åŒ–ã•ã‚ŒãŸåˆ†æãƒ‡ãƒ¼ã‚¿
        """
        try:
            # åˆ†æãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰JSONã‚’æŠ½å‡º
            analysis_text = analysis_data.get('analysis', '')
            
            # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œç´¢
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', analysis_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                parsed_json = json.loads(json_str)
            else:
                # JSONãƒ–ãƒ­ãƒƒã‚¯ãŒãªã„å ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’JSONã¨ã—ã¦è§£æã‚’è©¦è¡Œ
                try:
                    parsed_json = json.loads(analysis_text)
                except json.JSONDecodeError:
                    # JSONã¨ã—ã¦è§£æã§ããªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ§‹é€ ã‚’ä½œæˆ
                    parsed_json = self._extract_from_text(analysis_text)
            
            # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            structured = {
                'university_relation': parsed_json.get('university_relation', 'ä¸æ˜'),
                'relation_type': parsed_json.get('relation_type', 'ãã®ä»–'),
                'major_field': parsed_json.get('major_field', 'ä¸æ˜'),
                'personality_traits': json_to_text(parsed_json.get('personality_traits', [])),
                'learning_style': parsed_json.get('learning_style', ''),
                'activity_pattern': parsed_json.get('activity_pattern', ''),
                'collaboration_potential': parsed_json.get('collaboration_potential', 'ä¸æ˜'),
                'analysis_confidence': self._calculate_confidence(parsed_json),
                'raw_analysis_data': json_to_text(analysis_data)
            }
            
            logger.info(f"åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–: {structured['university_relation']}, {structured['major_field']}")
            return structured
            
        except Exception as e:
            logger.error(f"åˆ†æãƒ‡ãƒ¼ã‚¿è§£æã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ§‹é€ ã‚’è¿”ã™
            return {
                'university_relation': 'ä¸æ˜',
                'relation_type': 'ãã®ä»–',
                'major_field': 'ä¸æ˜',
                'personality_traits': '',
                'learning_style': '',
                'activity_pattern': '',
                'collaboration_potential': 'ä¸æ˜',
                'analysis_confidence': 0.0,
                'raw_analysis_data': json_to_text(analysis_data)
            }
    
    def _extract_from_text(self, text: str) -> Dict[str, Any]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åˆ†ææƒ…å ±ã‚’æŠ½å‡ºï¼ˆJSONãŒåˆ©ç”¨ã§ããªã„å ´åˆï¼‰
        
        Args:
            text: åˆ†æãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            æŠ½å‡ºã•ã‚ŒãŸæƒ…å ±ã®è¾æ›¸
        """
        result = {}
        
        # å¤§å­¦é–¢ä¿‚ã®åˆ¤å®š
        if 'æ±äº¬é€šä¿¡å¤§å­¦' in text or 'TOU' in text:
            result['university_relation'] = 'é«˜'
        elif 'å¤§å­¦' in text:
            result['university_relation'] = 'ä¸­'
        else:
            result['university_relation'] = 'ä½'
        
        # é–¢ä¿‚æ€§ã®åˆ¤å®š
        if 'å­¦ç”Ÿ' in text:
            result['relation_type'] = 'å­¦ç”Ÿ'
        elif 'æ•™å“¡' in text or 'å…ˆç”Ÿ' in text:
            result['relation_type'] = 'æ•™å“¡'
        else:
            result['relation_type'] = 'ãã®ä»–'
        
        # å°‚æ”»åˆ†é‡ã®åˆ¤å®š
        if 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°' in text or 'IT' in text or 'æƒ…å ±' in text:
            result['major_field'] = 'æƒ…å ±å­¦'
        elif 'çµŒå–¶' in text or 'ãƒ“ã‚¸ãƒã‚¹' in text:
            result['major_field'] = 'çµŒå–¶å­¦'
        else:
            result['major_field'] = 'ãã®ä»–'
        
        return result
    
    def _calculate_confidence(self, parsed_data: Dict[str, Any]) -> float:
        """
        åˆ†æçµæœã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—
        
        Args:
            parsed_data: è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0.0-1.0ï¼‰
        """
        confidence = 0.0
        
        # å¤§å­¦é–¢ä¿‚ã®æ˜ç¢ºã•
        if parsed_data.get('university_relation') == 'é«˜':
            confidence += 0.3
        elif parsed_data.get('university_relation') == 'ä¸­':
            confidence += 0.2
        
        # å°‚æ”»åˆ†é‡ã®ç‰¹å®šåº¦
        if parsed_data.get('major_field') not in ['ä¸æ˜', 'ãã®ä»–']:
            confidence += 0.2
        
        # èˆˆå‘³åˆ†é‡ã®æ•°
        interests = parsed_data.get('interests', [])
        if isinstance(interests, list) and len(interests) >= 3:
            confidence += 0.2
        
        # æŠ€è¡“ã‚¹ã‚­ãƒ«ã®ç‰¹å®š
        tech_skills = parsed_data.get('tech_skills', [])
        if isinstance(tech_skills, list) and len(tech_skills) >= 2:
            confidence += 0.2
        
        # æ€§æ ¼ç‰¹å¾´ã®è©³ç´°åº¦
        personality = parsed_data.get('personality_traits', [])
        if isinstance(personality, list) and len(personality) >= 2:
            confidence += 0.1
        
        return min(confidence, 1.0)
    
    def _create_analysis(self, user_id: int, structured_data: Dict[str, Any]) -> int:
        """æ–°è¦åˆ†æãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ"""
        query = """
            INSERT INTO user_analysis (
                user_id, university_relation, relation_type, major_field,
                personality_traits, learning_style, activity_pattern,
                collaboration_potential, analysis_confidence, raw_analysis_data
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        
        params = (
            user_id,
            structured_data['university_relation'],
            structured_data['relation_type'],
            structured_data['major_field'],
            structured_data['personality_traits'],
            structured_data['learning_style'],
            structured_data['activity_pattern'],
            structured_data['collaboration_potential'],
            structured_data['analysis_confidence'],
            structured_data['raw_analysis_data']
        )
        
        cursor = self.db.execute_query(query, params)
        analysis_id = cursor.lastrowid
        
        logger.info(f"æ–°è¦åˆ†æãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID {user_id} â†’ åˆ†æID {analysis_id}")
        return analysis_id
    
    def _update_analysis(self, analysis_id: int, structured_data: Dict[str, Any]) -> int:
        """æ—¢å­˜åˆ†æãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°"""
        query = """
            UPDATE user_analysis SET
                university_relation = ?, relation_type = ?, major_field = ?,
                personality_traits = ?, learning_style = ?, activity_pattern = ?,
                collaboration_potential = ?, analysis_confidence = ?, raw_analysis_data = ?,
                created_at = CURRENT_TIMESTAMP
            WHERE id = ?
        """
        
        params = (
            structured_data['university_relation'],
            structured_data['relation_type'],
            structured_data['major_field'],
            structured_data['personality_traits'],
            structured_data['learning_style'],
            structured_data['activity_pattern'],
            structured_data['collaboration_potential'],
            structured_data['analysis_confidence'],
            structured_data['raw_analysis_data'],
            analysis_id
        )
        
        self.db.execute_query(query, params)
        logger.info(f"åˆ†æãƒ¬ã‚³ãƒ¼ãƒ‰æ›´æ–°: åˆ†æID {analysis_id}")
        return analysis_id
    
    def get_latest_analysis(self, user_id: int) -> Optional[Dict[str, Any]]:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€æ–°åˆ†æçµæœã‚’å–å¾—
        
        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            
        Returns:
            æœ€æ–°ã®åˆ†æçµæœã¾ãŸã¯None
        """
        query = """
            SELECT * FROM user_analysis 
            WHERE user_id = ? 
            ORDER BY created_at DESC 
            LIMIT 1
        """
        return self.db.fetch_one(query, (user_id,))
    
    def get_analysis_by_id(self, analysis_id: int) -> Optional[Dict[str, Any]]:
        """
        åˆ†æIDã§åˆ†æçµæœã‚’å–å¾—
        
        Args:
            analysis_id: åˆ†æID
            
        Returns:
            åˆ†æçµæœã¾ãŸã¯None
        """
        query = "SELECT * FROM user_analysis WHERE id = ?"
        return self.db.fetch_one(query, (analysis_id,))
    
    def get_users_by_criteria(self, criteria: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        åˆ†æçµæœã®æ¡ä»¶ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ¤œç´¢
        
        Args:
            criteria: æ¤œç´¢æ¡ä»¶
            
        Returns:
            æ¡ä»¶ã«åˆè‡´ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åˆ†æçµæœãƒªã‚¹ãƒˆ
        """
        query = """
            SELECT ua.*, u.twitter_username, u.name 
            FROM user_analysis ua
            JOIN users u ON ua.user_id = u.id
            WHERE u.is_active = TRUE
        """
        params = []
        
        # æ¤œç´¢æ¡ä»¶ã‚’è¿½åŠ 
        if criteria.get('university_relation'):
            query += " AND ua.university_relation = ?"
            params.append(criteria['university_relation'])
        
        if criteria.get('major_field'):
            query += " AND ua.major_field = ?"
            params.append(criteria['major_field'])
        
        if criteria.get('relation_type'):
            query += " AND ua.relation_type = ?"
            params.append(criteria['relation_type'])
        
        if criteria.get('min_confidence'):
            query += " AND ua.analysis_confidence >= ?"
            params.append(criteria['min_confidence'])
        
        query += " ORDER BY ua.created_at DESC"
        
        return self.db.fetch_all(query, tuple(params))
    
    def get_analysis_statistics(self) -> Dict[str, Any]:
        """
        åˆ†æçµæœã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        
        Returns:
            çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
        """
        stats = {}
        
        # ç·åˆ†ææ•°
        total_result = self.db.fetch_one("SELECT COUNT(*) as count FROM user_analysis")
        stats['total_analyses'] = total_result['count'] if total_result else 0
        
        # å¤§å­¦é–¢ä¿‚è€…ã®åˆ†å¸ƒ
        relation_query = """
            SELECT university_relation, COUNT(*) as count 
            FROM user_analysis 
            GROUP BY university_relation
        """
        stats['university_relation_distribution'] = self.db.fetch_all(relation_query)
        
        # å°‚æ”»åˆ†é‡ã®åˆ†å¸ƒ
        major_query = """
            SELECT major_field, COUNT(*) as count 
            FROM user_analysis 
            GROUP BY major_field 
            ORDER BY count DESC
        """
        stats['major_field_distribution'] = self.db.fetch_all(major_query)
        
        # å¹³å‡ä¿¡é ¼åº¦
        confidence_result = self.db.fetch_one("SELECT AVG(analysis_confidence) as avg_confidence FROM user_analysis")
        stats['average_confidence'] = confidence_result['avg_confidence'] if confidence_result else 0.0
        
        return stats


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("ğŸ§ª AnalysisRepository ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
    db = DatabaseManager("test_analysis_repo.db")
    analysis_repo = AnalysisRepository(db)
    
    try:
        # ãƒ†ã‚¹ãƒˆç”¨åˆ†æãƒ‡ãƒ¼ã‚¿
        test_analysis_data = {
            'username': 'test_user',
            'analysis': '''```json
{
  "university_relation": "é«˜",
  "relation_type": "å­¦ç”Ÿ",
  "interests": ["ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°", "AI", "æ©Ÿæ¢°å­¦ç¿’"],
  "major_field": "æƒ…å ±å­¦",
  "personality_traits": ["è«–ç†çš„", "åŠ¹ç‡çš„"],
  "learning_style": "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã«é©å¿œ",
  "activity_pattern": "ç¶™ç¶šçš„ãªå­¦ç¿’",
  "tech_skills": ["Python", "JavaScript"],
  "collaboration_potential": "é«˜"
}
```'''
        }
        
        # 1. åˆ†æãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ†ã‚¹ãƒˆ
        print("âœ… åˆ†æãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ†ã‚¹ãƒˆ")
        analysis_id = analysis_repo.save_analysis(1, test_analysis_data)
        print(f"ä¿å­˜ã•ã‚ŒãŸåˆ†æID: {analysis_id}")
        
        # 2. åˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ
        print("âœ… åˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ")
        analysis = analysis_repo.get_latest_analysis(1)
        print(f"å–å¾—ã—ãŸåˆ†æ: {analysis['university_relation']}, {analysis['major_field']}")
        
        # 3. æ¡ä»¶æ¤œç´¢ãƒ†ã‚¹ãƒˆ
        print("âœ… æ¡ä»¶æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
        results = analysis_repo.get_users_by_criteria({'university_relation': 'é«˜'})
        print(f"å¤§å­¦é–¢ä¿‚è€…ï¼ˆé«˜ï¼‰: {len(results)}ä»¶")
        
        # 4. çµ±è¨ˆãƒ†ã‚¹ãƒˆ
        print("âœ… çµ±è¨ˆãƒ†ã‚¹ãƒˆ")
        stats = analysis_repo.get_analysis_statistics()
        print(f"ç·åˆ†ææ•°: {stats['total_analyses']}")
        print(f"å¹³å‡ä¿¡é ¼åº¦: {stats['average_confidence']:.2f}")
        
        print("ğŸ‰ AnalysisRepository ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    finally:
        db.close_connection()
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if os.path.exists("test_analysis_repo.db"):
            os.remove("test_analysis_repo.db")